{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.model_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path = [\"../../..\"] + sys.path # 切换到项目目录下\n",
    "\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import velovgi\n",
    "\n",
    "from ray import tune, air\n",
    "from ray.air import session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 目标函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import loggers\n",
    "from torch_geometric import seed_everything\n",
    "\n",
    "# TODO: 跳整多种参数，简化调参Trail的名字\n",
    "def train_velovgi(config):\n",
    "    # 提取参数\n",
    "    # 随机数种子，确保结果的可复现性\n",
    "    random_seed = config.get(\"random_seed\", 0)\n",
    "    # 预处理的参数\n",
    "    n_bnn_neighbors = config.get(\"n_bnn_neighbors\", 15)\n",
    "    n_knn_neighbors = config.get(\"n_knn_neighbors\", 15)\n",
    "    is_ot = config.get(\"is_ot\", True)\n",
    "    # 模型结构参数\n",
    "    n_hidden = config.get(\"n_hidden\", 256)\n",
    "    n_latent = config.get(\"n_latent\", 10)\n",
    "    n_layers = config.get(\"n_layers\", 1)\n",
    "    # 训练参数\n",
    "    num_neighbors = [config.get(\"num_neighbors\", 8)]*n_layers\n",
    "    max_epochs = config.get(\"max_epochs\", 10) # TODO:这里是最关键的一个参数，小epochs测试之后再提交到服务器上用大epoch\n",
    "    batch_size = config.get(\"batch_size\", 64)\n",
    "    max_kl_weight = config.get(\"max_kl_weight\", 0.8)\n",
    "\n",
    "    name = \"\"\n",
    "    for k,v in config.items():\n",
    "        name += \"%s_%s,\"%(k, v)\n",
    "    name = name[:-1]\n",
    "\n",
    "    # seed_everything(random_seed)\n",
    "    # # TODO:数据读入，对于不同的数据集这里需要替换\n",
    "    # adata_filename = \"/mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/data/erythroid_lineage.h5ad\" # 数据路径使用绝对路径\n",
    "    # adata = scv.read(adata_filename)\n",
    "    # batch_key = \"stage\" # 批次key\n",
    "    cluster_key = \"celltype\" # 细胞类型key\n",
    "    cluster_edges = [\n",
    "    (\"Blood progenitors 1\", \"Blood progenitors 2\"), \n",
    "    (\"Blood progenitors 2\", \"Erythroid1\"), \n",
    "    (\"Erythroid1\", \"Erythroid2\"), \n",
    "    (\"Erythroid2\", \"Erythroid3\")\n",
    "    ] # 指定对应数据集已知的细胞类型间的分化信息\n",
    "\n",
    "    # # TODO:预处理，这里batch_pair_list以后可能需要手动指定\n",
    "    # batch_list = list(adata.obs[batch_key].cat.categories)\n",
    "    # batch_pair_list = list(zip(batch_list[:-1], batch_list[1:]))\n",
    "    # subsample_adata = velovgi.pp.preprocess(adata,\n",
    "    #                                         n_bnn_neighbors=n_bnn_neighbors,\n",
    "    #                                         n_knn_neighbors=n_knn_neighbors,\n",
    "    #                                         batch_key=batch_key,\n",
    "    #                                         batch_pair_list=batch_pair_list,\n",
    "    #                                         is_ot=is_ot)\n",
    "    # TODO: 如果需要调整预处理之后的参数，就不需要重复做预处理了，读取预处理之后的结果即可\n",
    "    adata = velovgi.tl.read_adata(\"/mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/data/adata\")\n",
    "    subsample_adata = scv.read(\"/mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/data/subsample_adata.h5ad\") # 使用这个AnnData做训练\n",
    "    seed_everything(random_seed)\n",
    "\n",
    "    # 模型训练\n",
    "    logger = loggers.TensorBoardLogger(save_dir=\"./log\", name=name)\n",
    "    velovgi.tl.VELOVGI.setup_anndata(adata=subsample_adata, spliced_layer=\"Ms\", unspliced_layer=\"Mu\")\n",
    "    velovgi_model = velovgi.tl.VELOVGI(subsample_adata,\n",
    "                                       n_hidden=n_hidden,\n",
    "                                       n_latent=n_latent,\n",
    "                                       n_layers=n_layers)\n",
    "    velovgi_model.train(num_neighbors=num_neighbors,\n",
    "                        max_epochs=max_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        plan_kwargs={\"max_kl_weight\": max_kl_weight},\n",
    "                        logger=logger)\n",
    "\n",
    "    # 模型恢复\n",
    "    velovgi.tl.add_velovi_outputs_to_adata(subsample_adata, velovgi_model) # 模型输出\n",
    "    velovgi.pp.moment_recover(adata, subsample_adata) # 恢复\n",
    "\n",
    "    # 速率计算\n",
    "    scv.tl.velocity_graph(adata)\n",
    "    scv.pl.velocity_embedding(adata, color=cluster_key, title=name, save=\"arrow.png\")\n",
    "    scv.pl.velocity_embedding_stream(adata, color=cluster_key, title=name, legend_loc=\"right\", save=\"stream.png\")\n",
    "\n",
    "    # 伪时间计算\n",
    "    scv.tl.velocity_pseudotime(adata)\n",
    "    scv.pl.velocity_embedding_stream(adata, color=\"velocity_pseudotime\", title=name, colorbar=False, save=\"pseudotime.png\")\n",
    "\n",
    "\n",
    "    # 保存结果\n",
    "    subsample_adata.write(\"subsample_adata.h5ad\")\n",
    "    velovgi.tl.write_adata(adata, \"adata\")\n",
    "    velovgi_model.save(\"model\")\n",
    "\n",
    "    # 计算指标评价\n",
    "    adata_velo = velovgi.tl.pre_metric(adata)\n",
    "    exp_metrics = velovgi.tl.summary_metric(adata_velo, cluster_edges, cluster_key)[-1] # 计算指标汇总后的结果\n",
    "\n",
    "    session.report({\"CBDir\": exp_metrics[\"CBDir\"], \"ICVCoh\": exp_metrics[\"ICVCoh\"]})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 搜索空间，这里可以添加键值，实现更多层面的网格调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"max_epochs\" : tune.grid_search([40, 50]),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 执行调参，等待传入实验名称和搜索空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 15:24:25,495\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-06-10 15:24:27,213\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2023-06-10 15:24:27,228\tINFO tensorboardx.py:172 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-06-10 15:24:27,229\tWARNING callback.py:142 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-06-10 15:26:20</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:53.67        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.4/12.4 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: 0.8369767347720017<br>Logical resource usage: 0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_d505b_00001</td><td style=\"text-align: right;\">           1</td><td>/mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/tune/results/max_epochs_tune/train_velovgi_d505b_00001_1_max_epochs=50_2023-06-10_15-24-32/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   CBDir</th><th style=\"text-align: right;\">  ICVCoh</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_d505b_00000</td><td>TERMINATED</td><td>172.29.205.215:8846</td><td style=\"text-align: right;\">          40</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         108.199</td><td style=\"text-align: right;\">0.836977</td><td style=\"text-align: right;\">0.967631</td></tr>\n",
       "<tr><td>train_velovgi_d505b_00001</td><td>ERROR     </td><td>172.29.205.215:8910</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8846)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=8846)\u001b[0m /usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(pid=8846)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(pid=8846)\u001b[0m /usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "\u001b[2m\u001b[36m(pid=8846)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m load /mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/data/adata/adata.h5ad\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m load /mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/data/adata/sample_recover.pkl\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m 初始训练，初始化runner参数\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m choosing neighbor minibatch\n",
      "Epoch 1/40:   0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m Missing logger folder: ./log/max_epochs_40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40:   2%|▎         | 1/40 [00:01<01:07,  1.74s/it, loss=1.91e+06, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8910)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=8910)\u001b[0m /usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(pid=8910)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(pid=8910)\u001b[0m /usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "\u001b[2m\u001b[36m(pid=8910)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40:   5%|▌         | 2/40 [00:03<01:02,  1.63s/it, loss=1.87e+06, v_num=0]\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8910)\u001b[0m load /mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/data/adata/sample_recover.pkl\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8910)\u001b[0m load /mnt/h/F_bak/Python进阶/scRNA/Other/velovgi_workstation/notebook/local_pc/erythroid_lineage/data/adata/sample_recover.pkl\n",
      "Epoch 3/40:   8%|▊         | 3/40 [00:04<01:00,  1.62s/it, loss=1.85e+06, v_num=0]\n",
      "Epoch 4/40:   8%|▊         | 3/40 [00:04<01:00,  1.62s/it, loss=1.85e+06, v_num=0]\n",
      "Epoch 4/40:   8%|▊         | 3/40 [00:04<01:00,  1.62s/it, loss=1.85e+06, v_num=0]\n",
      "Epoch 4/40:   8%|▊         | 3/40 [00:04<01:00,  1.62s/it, loss=1.85e+06, v_num=0]\n",
      "Epoch 4/40:  10%|█         | 4/40 [00:06<00:58,  1.62s/it, loss=1.83e+06, v_num=0]\n",
      "Epoch 4/40:  10%|█         | 4/40 [00:06<00:58,  1.62s/it, loss=1.83e+06, v_num=0]\n",
      "Epoch 5/40:  10%|█         | 4/40 [00:06<00:58,  1.62s/it, loss=1.83e+06, v_num=0]\n",
      "Epoch 5/40:  12%|█▎        | 5/40 [00:08<00:57,  1.64s/it, loss=1.81e+06, v_num=0]\n",
      "Epoch 5/40:  12%|█▎        | 5/40 [00:08<00:57,  1.64s/it, loss=1.81e+06, v_num=0]\n",
      "Epoch 6/40:  12%|█▎        | 5/40 [00:08<00:57,  1.64s/it, loss=1.81e+06, v_num=0]\n",
      "Epoch 7/40:  15%|█▌        | 6/40 [00:09<00:55,  1.63s/it, loss=1.77e+06, v_num=0]\n",
      "Epoch 3/50:   6%|▌         | 3/50 [00:04<01:16,  1.63s/it, loss=1.85e+06, v_num=0]\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Epoch 8/40:  18%|█▊        | 7/40 [00:11<00:52,  1.60s/it, loss=1.74e+06, v_num=0]\n",
      "Epoch 4/50:   6%|▌         | 3/50 [00:04<01:16,  1.63s/it, loss=1.85e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 10/40:  25%|██▌       | 10/40 [00:16<00:49,  1.65s/it, loss=1.64e+06, v_num=0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "Epoch 11/40:  25%|██▌       | 10/40 [00:16<00:49,  1.65s/it, loss=1.64e+06, v_num=0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "Epoch 10/50:  18%|█▊        | 9/50 [00:14<01:08,  1.67s/it, loss=1.67e+06, v_num=0]\n",
      "Epoch 11/50:  20%|██        | 10/50 [00:16<01:08,  1.70s/it, loss=1.64e+06, v_num=0]\n",
      "Epoch 12/40:  30%|███       | 12/40 [00:19<00:46,  1.67s/it, loss=1.56e+06, v_num=0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Epoch 13/40:  30%|███       | 12/40 [00:19<00:46,  1.67s/it, loss=1.56e+06, v_num=0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Epoch 12/50:  22%|██▏       | 11/50 [00:18<01:10,  1.80s/it, loss=1.6e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 12/50:  24%|██▍       | 12/50 [00:21<01:16,  2.00s/it, loss=1.56e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 13/50:  24%|██▍       | 12/50 [00:21<01:16,  2.00s/it, loss=1.56e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 18/40:  42%|████▎     | 17/40 [00:30<00:48,  2.12s/it, loss=1.45e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 15/50:  30%|███       | 15/50 [00:27<01:12,  2.08s/it, loss=1.49e+06, v_num=0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Epoch 15/50:  28%|██▊       | 14/50 [00:25<01:17,  2.15s/it, loss=1.52e+06, v_num=0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Epoch 21/40:  50%|█████     | 20/40 [00:36<00:37,  1.85s/it, loss=1.38e+06, v_num=0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Epoch 18/50:  36%|███▌      | 18/50 [00:32<00:57,  1.79s/it, loss=1.42e+06, v_num=0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Epoch 22/40:  52%|█████▎    | 21/40 [00:37<00:33,  1.74s/it, loss=1.35e+06, v_num=0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Epoch 26/40:  62%|██████▎   | 25/40 [00:43<00:24,  1.61s/it, loss=1.25e+06, v_num=0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "Epoch 26/40:  62%|██████▎   | 25/40 [00:43<00:24,  1.61s/it, loss=1.25e+06, v_num=0]\n",
      "Epoch 26/40:  65%|██████▌   | 26/40 [00:45<00:22,  1.63s/it, loss=1.22e+06, v_num=0]\n",
      "Epoch 27/40:  65%|██████▌   | 26/40 [00:45<00:22,  1.63s/it, loss=1.22e+06, v_num=0]\n",
      "Epoch 27/40:  68%|██████▊   | 27/40 [00:46<00:21,  1.62s/it, loss=1.2e+06, v_num=0] \n",
      "Epoch 28/40:  68%|██████▊   | 27/40 [00:47<00:21,  1.62s/it, loss=1.2e+06, v_num=0]\n",
      "Epoch 29/40:  70%|███████   | 28/40 [00:49<00:21,  1.79s/it, loss=1.18e+06, v_num=0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Epoch 26/50:  52%|█████▏    | 26/50 [00:48<00:58,  2.44s/it, loss=1.25e+06, v_num=0]\n",
      "Epoch 29/40:  72%|███████▎  | 29/40 [00:53<00:27,  2.47s/it, loss=1.16e+06, v_num=0]\n",
      "Epoch 26/50:  52%|█████▏    | 26/50 [00:48<00:58,  2.44s/it, loss=1.22e+06, v_num=0]\n",
      "Epoch 30/40:  75%|███████▌  | 30/40 [00:55<00:24,  2.42s/it, loss=1.15e+06, v_num=0]\n",
      "Epoch 30/40:  75%|███████▌  | 30/40 [00:55<00:24,  2.42s/it, loss=1.15e+06, v_num=0]\n",
      "Epoch 28/50:  54%|█████▍    | 27/50 [00:50<00:56,  2.46s/it, loss=1.2e+06, v_num=0] \n",
      "Epoch 32/40:  80%|████████  | 32/40 [00:59<00:16,  2.11s/it, loss=1.12e+06, v_num=0]\n",
      "Epoch 31/40:  75%|███████▌  | 30/40 [00:55<00:24,  2.42s/it, loss=1.15e+06, v_num=0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Epoch 33/40:  82%|████████▎ | 33/40 [01:01<00:14,  2.03s/it, loss=1.1e+06, v_num=0] \n",
      "Epoch 30/50:  58%|█████▊    | 29/50 [00:54<00:45,  2.18s/it, loss=1.16e+06, v_num=0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Epoch 35/40:  85%|████████▌ | 34/40 [01:02<00:11,  1.97s/it, loss=1.08e+06, v_num=0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Epoch 35/40:  88%|████████▊ | 35/40 [01:04<00:09,  1.89s/it, loss=1.07e+06, v_num=0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Epoch 37/40:  90%|█████████ | 36/40 [01:06<00:07,  1.81s/it, loss=1.05e+06, v_num=0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Epoch 38/40:  92%|█████████▎| 37/40 [01:07<00:05,  1.75s/it, loss=1.04e+06, v_num=0]\n",
      "Epoch 38/40:  95%|█████████▌| 38/40 [01:09<00:03,  1.77s/it, loss=1.02e+06, v_num=0]\n",
      "Epoch 34/50:  66%|██████▌   | 33/50 [01:01<00:30,  1.79s/it, loss=1.1e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 39/40:  95%|█████████▌| 38/40 [01:09<00:03,  1.77s/it, loss=1.02e+06, v_num=0]\n",
      "Epoch 39/40:  98%|█████████▊| 39/40 [01:11<00:01,  1.80s/it, loss=1.01e+06, v_num=0]\n",
      "Epoch 39/40:  98%|█████████▊| 39/40 [01:11<00:01,  1.80s/it, loss=1.01e+06, v_num=0]\n",
      "Epoch 36/50:  70%|███████   | 35/50 [01:04<00:26,  1.77s/it, loss=1.07e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 40/40:  98%|█████████▊| 39/40 [01:11<00:01,  1.80s/it, loss=1.01e+06, v_num=0]\n",
      "Epoch 40/40: 100%|██████████| 40/40 [01:13<00:00,  1.84s/it, loss=9.93e+05, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8910)\u001b[0m `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8910)\u001b[0m `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8910)\u001b[0m `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8910)\u001b[0m `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8910)\u001b[0m `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "2023-06-10 15:25:49,895\tERROR trial_runner.py:1450 -- Trial train_velovgi_d505b_00001: Error happened when processing _ExecutorEventType.TRAINING_RESULT.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1231, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2523, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.29.205.215, ID: 2a97e891dee2655b045830313aa387420a682a8acb44b58ba0d90210) where the task (actor ID: 24834c27f254c870697a7a3401000000, name=ImplicitFunc.__init__, pid=8910, memory used=0.66GB) was running was 11.79GB / 12.39GB (0.951148), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 727d32d313bac61a6e208e06bbd472f59c425908a07b54af7cdbb6a3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.29.205.215`. To see the logs of the worker, use `ray logs worker-727d32d313bac61a6e208e06bbd472f59c425908a07b54af7cdbb6a3*out -ip 172.29.205.215. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "25116\t1.49\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9003 --cont...\n",
      "24944\t1.49\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9033 --cont...\n",
      "340\t1.44\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9003 --cont...\n",
      "1460\t1.40\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9058 --cont...\n",
      "312\t0.95\t/root/.vscode-server/bin/b380da4ef1ee00e224a15c1d4d9793e27c2b6302/node /root/.vscode-server/extensio...\n",
      "8846\t0.69\tray::ImplicitFunc.train\n",
      "8910\t0.66\tray::ImplicitFunc.train\n",
      "24878\t0.46\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9023 --cont...\n",
      "924\t0.43\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9053 --cont...\n",
      "8011\t0.38\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9043 --cont...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>CBDir             </th><th>ICVCoh            </th><th>date               </th><th>done  </th><th>experiment_tag  </th><th>hostname       </th><th>iterations_since_restore  </th><th>node_ip       </th><th style=\"text-align: right;\">  pid</th><th>time_since_restore  </th><th>time_this_iter_s  </th><th>time_total_s      </th><th style=\"text-align: right;\">  timestamp</th><th>training_iteration  </th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_d505b_00000</td><td>0.8369767347720017</td><td>0.9676312586003908</td><td>2023-06-10_15-26-20</td><td>True  </td><td>0_max_epochs=40 </td><td>DESKTOP-9GVJMSD</td><td>1                         </td><td>172.29.205.215</td><td style=\"text-align: right;\"> 8846</td><td>108.19876480102539  </td><td>108.19876480102539</td><td>108.19876480102539</td><td style=\"text-align: right;\"> 1686381980</td><td>1                   </td><td>d505b_00000</td></tr>\n",
       "<tr><td>train_velovgi_d505b_00001</td><td>                  </td><td>                  </td><td>2023-06-10_15-24-38</td><td>      </td><td>                </td><td>DESKTOP-9GVJMSD</td><td>                          </td><td>172.29.205.215</td><td style=\"text-align: right;\"> 8910</td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1686381878</td><td>                    </td><td>d505b_00001</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 15:25:49,962\tERROR ray_trial_executor.py:883 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
      "  File \"/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 874, in _resolve_stop_event\n",
      "    ray.get(future, timeout=timeout)\n",
      "  File \"/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2523, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.29.205.215, ID: 2a97e891dee2655b045830313aa387420a682a8acb44b58ba0d90210) where the task (actor ID: 24834c27f254c870697a7a3401000000, name=ImplicitFunc.__init__, pid=8910, memory used=0.66GB) was running was 11.79GB / 12.39GB (0.951148), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 727d32d313bac61a6e208e06bbd472f59c425908a07b54af7cdbb6a3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.29.205.215`. To see the logs of the worker, use `ray logs worker-727d32d313bac61a6e208e06bbd472f59c425908a07b54af7cdbb6a3*out -ip 172.29.205.215. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "25116\t1.49\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9003 --cont...\n",
      "24944\t1.49\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9033 --cont...\n",
      "340\t1.44\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9003 --cont...\n",
      "1460\t1.40\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9058 --cont...\n",
      "312\t0.95\t/root/.vscode-server/bin/b380da4ef1ee00e224a15c1d4d9793e27c2b6302/node /root/.vscode-server/extensio...\n",
      "8846\t0.69\tray::ImplicitFunc.train\n",
      "8910\t0.66\tray::ImplicitFunc.train\n",
      "24878\t0.46\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9023 --cont...\n",
      "924\t0.43\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9053 --cont...\n",
      "8011\t0.38\t/usr/local/conda/envs/velovi-env/bin/python -m ipykernel_launcher --ip=127.0.0.1 --stdin=9043 --cont...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m computing velocity graph (using 1/12 cores)\n",
      "Epoch 38/50:  74%|███████▍  | 37/50 [01:08<00:24,  1.86s/it, loss=1.04e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m   0%|          | 0/500 [00:00<?, ?cells/s]\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m     finished (0:00:01) --> added \n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m     'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m computing velocity embedding\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m     finished (0:00:00) --> added\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m     'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m saving figure to file ./figures/scvelo_arrow.png\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m Figure(640x480)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m saving figure to file ./figures/scvelo_stream.png\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m Figure(640x480)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m saving figure to file ./figures/scvelo_pseudotime.png\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m Figure(640x480)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m create adata\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m save adata/sample_recover.pkl\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=8846)\u001b[0m save adata/adata.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 15:26:20,917\tERROR tune.py:941 -- Trials did not complete: [train_velovgi_d505b_00001]\n",
      "2023-06-10 15:26:20,917\tINFO tune.py:945 -- Total run time: 113.70 seconds (113.65 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-10 15:26:25,461 E 8187 8187] (raylet) node_manager.cc:3071: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 2a97e891dee2655b045830313aa387420a682a8acb44b58ba0d90210, IP: 172.29.205.215) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.29.205.215`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "name = \"max_epochs_tune\" # TODO:指定此次调参的名字，这里是预处理过程的调参\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_velovgi,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"CBDir\",\n",
    "        mode=\"max\",\n",
    "        scheduler=ASHAScheduler()\n",
    "    ),\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir=\"./results\", # Trail内部具体输出结果在这里保存\n",
    "        name=name # 开启调参的Tensorboard日志\n",
    "    ),\n",
    "    param_space=search_space,\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velovi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
