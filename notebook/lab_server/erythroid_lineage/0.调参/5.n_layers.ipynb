{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../data/adata//adata.h5ad\n",
      "load ../data/adata//sample_recover.pkl\n"
     ]
    }
   ],
   "source": [
    "import base\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 07:04:47,148\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-06-02 07:04:47,709\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2023-06-02 07:04:47,750\tINFO tensorboardx.py:172 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-06-02 07:04:47,751\tWARNING callback.py:142 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-06-02 07:12:51</td></tr>\n",
       "<tr><td>Running for: </td><td>00:08:03.38        </td></tr>\n",
       "<tr><td>Memory:      </td><td>22.0/62.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Logical resource usage: 3.0/24 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  n_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_b48e8_00000</td><td>RUNNING </td><td>192.168.1.2:1020157</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>train_velovgi_b48e8_00001</td><td>RUNNING </td><td>192.168.1.2:1020268</td><td style=\"text-align: right;\">         2</td></tr>\n",
       "<tr><td>train_velovgi_b48e8_00002</td><td>RUNNING </td><td>192.168.1.2:1020269</td><td style=\"text-align: right;\">         3</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1020157)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=1020157)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(pid=1020157)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(pid=1020157)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "\u001b[2m\u001b[36m(pid=1020157)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=1020157)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=1020157)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=1020157)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=1020157)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=1020157)\u001b[0m Missing logger folder: ./log/n_layers_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=1020157)\u001b[0m 初始训练，初始化runner参数\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=1020157)\u001b[0m choosing neighbor minibatch\n",
      "Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1020269)\u001b[0m Global seed set to 0\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1020269)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1020269)\u001b[0m   new_rank_zero_deprecation(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1020269)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1020269)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500:   0%|          | 1/500 [00:18<2:37:41, 18.96s/it, loss=1.89e+06, v_num=0]\n",
      "\u001b[2m\u001b[36m(pid=1020269)\u001b[0m load ../data/adata//adata.h5ad\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1020269)\u001b[0m load ../data/adata//sample_recover.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=1020269)\u001b[0m 初始训练，初始化runner参数\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=1020269)\u001b[0m choosing neighbor minibatch\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/500:   0%|          | 1/500 [00:26<3:41:14, 26.60s/it, loss=1.88e+06, v_num=0]\n",
      "Epoch 3/500:   0%|          | 2/500 [00:38<2:40:10, 19.30s/it, loss=1.61e+06, v_num=0]\n",
      "Epoch 3/500:   0%|          | 2/500 [00:53<3:41:00, 26.63s/it, loss=1.6e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 3/500:   0%|          | 2/500 [01:10<4:52:10, 35.20s/it, loss=1.58e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 4/500:   1%|          | 3/500 [01:20<3:41:16, 26.71s/it, loss=1.38e+06, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 6/500:   1%|          | 5/500 [01:36<2:40:30, 19.46s/it, loss=1.08e+06, v_num=0]\n",
      "Epoch 4/500:   1%|          | 3/500 [01:45<4:52:57, 35.37s/it, loss=1.37e+06, v_num=0]\n",
      "Epoch 7/500:   1%|          | 6/500 [01:56<2:40:21, 19.48s/it, loss=9.28e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 8/500:   1%|▏         | 7/500 [02:16<2:40:57, 19.59s/it, loss=8.11e+05, v_num=0]\n",
      "Epoch 6/500:   1%|          | 5/500 [02:13<3:41:02, 26.79s/it, loss=1.09e+06, v_num=0]\n",
      "Epoch 5/500:   1%|          | 4/500 [02:21<4:51:58, 35.32s/it, loss=1.25e+06, v_num=0]\n",
      "Epoch 9/500:   2%|▏         | 8/500 [02:35<2:40:37, 19.59s/it, loss=7.68e+05, v_num=0]\n",
      "Epoch 7/500:   1%|          | 6/500 [02:40<3:40:42, 26.81s/it, loss=9.26e+05, v_num=0]\n",
      "Epoch 10/500:   2%|▏         | 9/500 [02:55<2:40:55, 19.66s/it, loss=7.39e+05, v_num=0]\n",
      "Epoch 8/500:   1%|▏         | 7/500 [03:07<3:40:09, 26.79s/it, loss=8.09e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 12/500:   2%|▏         | 11/500 [03:35<2:41:38, 19.83s/it, loss=6.94e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 13/500:   2%|▏         | 12/500 [03:55<2:41:50, 19.90s/it, loss=6.75e+05, v_num=0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Epoch 10/500:   2%|▏         | 9/500 [04:00<3:39:22, 26.81s/it, loss=7.37e+05, v_num=0]\n",
      "Epoch 8/500:   1%|▏         | 7/500 [04:06<4:49:20, 35.21s/it, loss=8.13e+05, v_num=0]\n",
      "Epoch 11/500:   2%|▏         | 10/500 [04:28<3:39:40, 26.90s/it, loss=7.13e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 9/500:   2%|▏         | 8/500 [04:42<4:48:46, 35.22s/it, loss=7.69e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 16/500:   3%|▎         | 15/500 [04:55<2:42:06, 20.06s/it, loss=6.26e+05, v_num=0]\n",
      "Epoch 12/500:   2%|▏         | 11/500 [04:55<3:39:38, 26.95s/it, loss=6.93e+05, v_num=0]\n",
      "Epoch 17/500:   3%|▎         | 16/500 [05:16<2:42:05, 20.09s/it, loss=6.11e+05, v_num=0]\n",
      "Epoch 10/500:   2%|▏         | 9/500 [05:16<4:47:26, 35.13s/it, loss=7.4e+05, v_num=0]\n",
      "Epoch 13/500:   2%|▏         | 12/500 [05:22<3:40:10, 27.07s/it, loss=6.74e+05, v_num=0]\n",
      "Epoch 18/500:   3%|▎         | 17/500 [05:36<2:41:50, 20.11s/it, loss=5.96e+05, v_num=0]\n",
      "Epoch 14/500:   3%|▎         | 13/500 [05:49<3:40:23, 27.15s/it, loss=6.57e+05, v_num=0]\n",
      "Epoch 19/500:   4%|▎         | 18/500 [05:56<2:41:19, 20.08s/it, loss=5.81e+05, v_num=0]\n",
      "Epoch 20/500:   4%|▍         | 19/500 [06:16<2:40:57, 20.08s/it, loss=5.68e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 12/500:   2%|▏         | 11/500 [06:29<4:51:08, 35.72s/it, loss=6.94e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 16/500:   3%|▎         | 15/500 [06:44<3:39:46, 27.19s/it, loss=6.24e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 22/500:   4%|▍         | 21/500 [06:56<2:40:55, 20.16s/it, loss=5.4e+05, v_num=0] \n",
      "Epoch 13/500:   2%|▏         | 12/500 [07:06<4:52:42, 35.99s/it, loss=6.76e+05, v_num=0]\n",
      "Epoch 17/500:   3%|▎         | 16/500 [07:11<3:39:36, 27.22s/it, loss=6.09e+05, v_num=0]\n",
      "Epoch 23/500:   4%|▍         | 22/500 [07:16<2:40:06, 20.10s/it, loss=5.27e+05, v_num=0]\n",
      "Epoch 24/500:   5%|▍         | 23/500 [07:36<2:39:39, 20.08s/it, loss=5.14e+05, v_num=0]\n",
      "Epoch 18/500:   3%|▎         | 17/500 [07:38<3:39:27, 27.26s/it, loss=5.94e+05, v_num=0]\n",
      "Epoch 25/500:   5%|▍         | 24/500 [07:56<2:39:18, 20.08s/it, loss=5.01e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 23/500:   4%|▍         | 22/500 [09:53<3:35:03, 26.99s/it, loss=5.26e+05, v_num=0]\n",
      "Epoch 31/500:   6%|▌         | 30/500 [09:58<2:38:40, 20.26s/it, loss=4.37e+05, v_num=0]\n",
      "Epoch 34/500:   7%|▋         | 33/500 [10:58<2:36:41, 20.13s/it, loss=4.12e+05, v_num=0]\n",
      "Epoch 37/500:   7%|▋         | 36/500 [11:59<2:36:04, 20.18s/it, loss=3.9e+05, v_num=0] \n",
      "Epoch 32/500:   6%|▌         | 31/500 [13:54<3:30:10, 26.89s/it, loss=4.28e+05, v_num=0]\n",
      "Epoch 26/500:   5%|▌         | 25/500 [14:53<4:38:05, 35.13s/it, loss=4.89e+05, v_num=0]\n",
      "Epoch 38/500:   7%|▋         | 37/500 [21:54<4:31:03, 35.13s/it, loss=3.83e+05, v_num=0]\n",
      "Epoch 52/500:  10%|█         | 51/500 [22:54<3:21:37, 26.94s/it, loss=2.92e+05, v_num=0]\n",
      "Epoch 89/500:  18%|█▊        | 89/500 [29:57<2:21:06, 20.60s/it, loss=1.32e+05, v_num=0]\n",
      "Epoch 89/500:  18%|█▊        | 89/500 [29:57<2:21:06, 20.60s/it, loss=1.32e+05, v_num=0]\n",
      "Epoch 90/500:  18%|█▊        | 89/500 [29:57<2:21:06, 20.60s/it, loss=1.32e+05, v_num=0]\n",
      "Epoch 93/500:  18%|█▊        | 92/500 [30:58<2:18:52, 20.42s/it, loss=1.24e+05, v_num=0]\n",
      "Epoch 72/500:  14%|█▍        | 71/500 [31:52<3:12:23, 26.91s/it, loss=2.08e+05, v_num=0]\n",
      "Epoch 99/500:  20%|█▉        | 98/500 [32:59<2:15:06, 20.16s/it, loss=1.09e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 58/500:  11%|█▏        | 57/500 [33:53<4:27:27, 36.23s/it, loss=2.61e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 81/500:  16%|█▌        | 80/500 [35:55<3:08:48, 26.97s/it, loss=1.61e+05, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 101/500:  20%|██        | 100/500 [44:54<2:59:25, 26.91s/it, loss=1.03e+05, v_num=0]\n",
      "Epoch 87/500:  17%|█▋        | 86/500 [50:53<4:02:24, 35.13s/it, loss=1.4e+05, v_num=0] \n",
      "Epoch 155/500:  31%|███       | 154/500 [51:59<1:57:23, 20.36s/it, loss=2.9e+04, v_num=0] \n",
      "Epoch 121/500:  24%|██▍       | 120/500 [53:54<2:50:46, 26.96s/it, loss=6.53e+04, v_num=0]\n",
      "Epoch 99/500:  20%|█▉        | 98/500 [57:54<3:54:57, 35.07s/it, loss=1.06e+05, v_num=0]\n",
      "Epoch 141/500:  28%|██▊       | 140/500 [1:02:54<2:42:00, 27.00s/it, loss=4.08e+04, v_num=0]\n",
      "Epoch 208/500:  41%|████▏     | 207/500 [1:09:59<1:39:53, 20.46s/it, loss=1.1e+04, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 121/500:  24%|██▍       | 120/500 [1:10:54<3:44:26, 35.44s/it, loss=6.44e+04, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 161/500:  32%|███▏      | 160/500 [1:11:55<2:33:12, 27.04s/it, loss=2.45e+04, v_num=0]\n",
      "Epoch 133/500:  26%|██▋       | 132/500 [1:17:55<3:35:07, 35.07s/it, loss=4.82e+04, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 221/500:  44%|████▍     | 220/500 [1:38:55<2:05:42, 26.94s/it, loss=1.01e+04, v_num=0]\n",
      "Epoch 308/500:  61%|██████▏   | 307/500 [1:43:55<1:05:23, 20.33s/it, loss=4.61e+03, v_num=0]\n",
      "Epoch 232/500:  46%|████▌     | 231/500 [1:43:52<2:01:04, 27.00s/it, loss=9.32e+03, v_num=0]\n",
      "Epoch 179/500:  36%|███▌      | 178/500 [1:44:51<3:08:50, 35.19s/it, loss=1.5e+04, v_num=0] \n",
      "Epoch 314/500:  63%|██████▎   | 313/500 [1:45:58<1:03:31, 20.38s/it, loss=4.32e+03, v_num=0]\n",
      "Epoch 317/500:  63%|██████▎   | 316/500 [1:46:59<1:02:32, 20.40s/it, loss=4.15e+03, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 191/500:  38%|███▊      | 190/500 [1:51:53<3:01:06, 35.05s/it, loss=1.22e+04, v_num=0]\n",
      "Epoch 252/500:  50%|█████     | 251/500 [1:52:53<1:52:05, 27.01s/it, loss=8.04e+03, v_num=0]\n",
      "Epoch 203/500:  40%|████      | 202/500 [1:58:54<2:54:34, 35.15s/it, loss=1.13e+04, v_num=0]\n",
      "Epoch 364/500:  73%|███████▎  | 363/500 [2:02:58<46:53, 20.54s/it, loss=1.87e+03, v_num=0]\n",
      "Epoch 283/500:  56%|█████▋    | 282/500 [2:06:53<1:38:25, 27.09s/it, loss=6.08e+03, v_num=0]\n",
      "Epoch 408/500:  81%|████████▏ | 407/500 [2:17:57<31:38, 20.42s/it, loss=202, v_num=0]\n",
      "Epoch 411/500:  82%|████████▏ | 410/500 [2:18:59<30:42, 20.47s/it, loss=272, v_num=0]\n",
      "Epoch 256/500:  51%|█████     | 255/500 [2:29:54<2:23:45, 35.20s/it, loss=7.6e+03, v_num=0] \n",
      "Epoch 455/500:  91%|█████████ | 454/500 [2:33:59<15:43, 20.52s/it, loss=157, v_num=0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 345/500:  69%|██████▉   | 344/500 [2:34:54<1:10:34, 27.15s/it, loss=2.77e+03, v_num=0]\n",
      "Epoch 499/500: 100%|█████████▉| 498/500 [2:48:59<00:40, 20.46s/it, loss=79.2, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 11:25:14,670\tINFO tune.py:945 -- Total run time: 15626.96 seconds (15626.91 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "name = \"n_layers_adjust\"\n",
    "search_space = {\"n_layers\": tune.grid_search([1, 2, 3])}\n",
    "results = base.hyperparameter_tuner(name, search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_result().config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velovi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
