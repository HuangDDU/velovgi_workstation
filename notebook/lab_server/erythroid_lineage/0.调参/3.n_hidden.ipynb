{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../data/adata//adata.h5ad\n",
      "load ../data/adata//sample_recover.pkl\n"
     ]
    }
   ],
   "source": [
    "import base\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:14:37,415\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-06-01 20:14:38,228\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2023-06-01 20:14:38,263\tINFO tensorboardx.py:172 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-06-01 20:14:38,264\tWARNING callback.py:142 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-06-01 23:17:19</td></tr>\n",
       "<tr><td>Running for: </td><td>03:02:41.54        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.8/62.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: 0.7243772767743031<br>Logical resource usage: 0/24 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_e1172_00002</td><td style=\"text-align: right;\">           1</td><td>/home/huang/PyCode/scRNA/Other/velovgi_workstation/notebook/lab_server/erythroid_lineage/0.调参/results/n_hidden_adjust/train_velovgi_e1172_00002_2_n_hidden=1024_2023-06-01_20-14-43/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  n_hidden</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   CBDir</th><th style=\"text-align: right;\">  ICVCoh</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_e1172_00000</td><td>TERMINATED</td><td>192.168.1.2:701933</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9994.48</td><td style=\"text-align: right;\">0.725216</td><td style=\"text-align: right;\">0.994215</td></tr>\n",
       "<tr><td>train_velovgi_e1172_00001</td><td>TERMINATED</td><td>192.168.1.2:703982</td><td style=\"text-align: right;\">       512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10950.9 </td><td style=\"text-align: right;\">0.721862</td><td style=\"text-align: right;\">0.994582</td></tr>\n",
       "<tr><td>train_velovgi_e1172_00002</td><td>ERROR     </td><td>192.168.1.2:703984</td><td style=\"text-align: right;\">      1024</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=701933)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=701933)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(pid=701933)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(pid=701933)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "\u001b[2m\u001b[36m(pid=701933)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m Missing logger folder: ./log/n_hidden_256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m 初始训练，初始化runner参数\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m choosing neighbor minibatch\n",
      "Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=703982)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=703984)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=703982)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=703982)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=703982)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=703982)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=703984)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(pid=703984)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(pid=703984)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "\u001b[2m\u001b[36m(pid=703984)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=703982)\u001b[0m load ../data/adata//sample_recover.pkl\n",
      "\u001b[2m\u001b[36m(pid=703982)\u001b[0m load ../data/adata//sample_recover.pkl\n",
      "\u001b[2m\u001b[36m(pid=703984)\u001b[0m load ../data/adata//adata.h5ad\n",
      "\u001b[2m\u001b[36m(pid=703984)\u001b[0m load ../data/adata//sample_recover.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Missing logger folder: ./log/n_hidden_512\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Missing logger folder: ./log/n_hidden_512\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Missing logger folder: ./log/n_hidden_512\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Missing logger folder: ./log/n_hidden_512\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Missing logger folder: ./log/n_hidden_512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m choosing neighbor minibatch\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m choosing neighbor minibatch\n",
      "Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703984)\u001b[0m 初始训练，初始化runner参数\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703984)\u001b[0m choosing neighbor minibatch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=703984)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703984)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703984)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703984)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703984)\u001b[0m Missing logger folder: ./log/n_hidden_1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500:   0%|          | 1/500 [00:21<3:00:54, 21.75s/it, loss=1.89e+06, v_num=0]\n",
      "Epoch 2/500:   0%|          | 1/500 [00:21<3:00:54, 21.75s/it, loss=1.89e+06, v_num=0]\n",
      "Epoch 1/500:   0%|          | 1/500 [00:29<4:03:24, 29.27s/it]\n",
      "Epoch 1/500:   0%|          | 1/500 [00:29<4:03:24, 29.27s/it, loss=1.87e+06, v_num=0]\n",
      "Epoch 2/500:   0%|          | 1/500 [00:29<4:03:24, 29.27s/it, loss=1.87e+06, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:15:23,307\tERROR trial_runner.py:1450 -- Trial train_velovgi_e1172_00002: Error happened when processing _ExecutorEventType.TRAINING_RESULT.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1231, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2523, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 192.168.1.2, ID: 642fe9b97e54af359325ce8b51aa131a5276790d3d59a80fd2d66dbc) where the task (actor ID: af79625946938e6faa8f55c201000000, name=ImplicitFunc.__init__, pid=703984, memory used=2.06GB) was running was 59.45GB / 62.55GB (0.950494), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 4744c6f7f04fc3dbcad573660129f93b2f642f9576cff5c9785f983a) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 192.168.1.2`. To see the logs of the worker, use `ray logs worker-4744c6f7f04fc3dbcad573660129f93b2f642f9576cff5c9785f983a*out -ip 192.168.1.2. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "703984\t2.06\tray::ImplicitFunc.train\n",
      "695239\t1.93\tray::ImplicitFunc.train\n",
      "695240\t1.93\tray::ImplicitFunc.train\n",
      "703982\t1.91\tray::ImplicitFunc.train\n",
      "704886\t1.89\tray::ImplicitFunc.train\n",
      "704821\t1.84\tray::ImplicitFunc.train\n",
      "695163\t1.84\tray::ImplicitFunc.train\n",
      "674446\t1.82\tray::ImplicitFunc.train\n",
      "701933\t1.81\tray::ImplicitFunc.train\n",
      "703825\t1.81\tray::ImplicitFunc.train\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>date               </th><th>hostname  </th><th>node_ip    </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_e1172_00002</td><td>2023-06-01_20-14-48</td><td>yu        </td><td>192.168.1.2</td><td style=\"text-align: right;\">703984</td><td style=\"text-align: right;\"> 1685621688</td><td>e1172_00002</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:15:23,343\tERROR ray_trial_executor.py:883 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
      "  File \"/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 874, in _resolve_stop_event\n",
      "    ray.get(future, timeout=timeout)\n",
      "  File \"/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/worker.py\", line 2523, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 192.168.1.2, ID: 642fe9b97e54af359325ce8b51aa131a5276790d3d59a80fd2d66dbc) where the task (actor ID: af79625946938e6faa8f55c201000000, name=ImplicitFunc.__init__, pid=703984, memory used=2.06GB) was running was 59.45GB / 62.55GB (0.950494), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 4744c6f7f04fc3dbcad573660129f93b2f642f9576cff5c9785f983a) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 192.168.1.2`. To see the logs of the worker, use `ray logs worker-4744c6f7f04fc3dbcad573660129f93b2f642f9576cff5c9785f983a*out -ip 192.168.1.2. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "703984\t2.06\tray::ImplicitFunc.train\n",
      "695239\t1.93\tray::ImplicitFunc.train\n",
      "695240\t1.93\tray::ImplicitFunc.train\n",
      "703982\t1.91\tray::ImplicitFunc.train\n",
      "704886\t1.89\tray::ImplicitFunc.train\n",
      "704821\t1.84\tray::ImplicitFunc.train\n",
      "695163\t1.84\tray::ImplicitFunc.train\n",
      "674446\t1.82\tray::ImplicitFunc.train\n",
      "701933\t1.81\tray::ImplicitFunc.train\n",
      "703825\t1.81\tray::ImplicitFunc.train\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500:   0%|          | 2/500 [00:45<3:11:40, 23.09s/it, loss=1.61e+06, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-01 20:15:37,384 E 701083 701083] (raylet) node_manager.cc:3071: 4 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 642fe9b97e54af359325ce8b51aa131a5276790d3d59a80fd2d66dbc, IP: 192.168.1.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 192.168.1.2`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m `Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████| 500/500 [2:39:36<00:00, 19.15s/it, loss=55.7, v_num=0]\n",
      "Epoch 427/500:  85%|████████▌ | 426/500 [2:39:46<27:09, 22.02s/it, loss=252, v_num=0]\n",
      "Epoch 428/500:  85%|████████▌ | 427/500 [2:40:07<26:41, 21.94s/it, loss=219, v_num=0]\n",
      "Epoch 429/500:  86%|████████▌ | 428/500 [2:40:29<26:05, 21.75s/it, loss=253, v_num=0]\n",
      "Epoch 430/500:  86%|████████▌ | 429/500 [2:40:50<25:34, 21.62s/it, loss=224, v_num=0]\n",
      "Epoch 431/500:  86%|████████▌ | 430/500 [2:41:12<25:10, 21.58s/it, loss=272, v_num=0]\n",
      "Epoch 432/500:  86%|████████▌ | 431/500 [2:41:33<24:47, 21.56s/it, loss=239, v_num=0]\n",
      "Epoch 433/500:  86%|████████▋ | 432/500 [2:41:54<24:23, 21.53s/it, loss=180, v_num=0]\n",
      "Epoch 434/500:  87%|████████▋ | 433/500 [2:42:16<24:02, 21.52s/it, loss=226, v_num=0]\n",
      "Epoch 435/500:  87%|████████▋ | 434/500 [2:42:37<23:39, 21.51s/it, loss=241, v_num=0]\n",
      "Epoch 436/500:  87%|████████▋ | 435/500 [2:42:59<23:20, 21.54s/it, loss=193, v_num=0]\n",
      "Epoch 437/500:  87%|████████▋ | 436/500 [2:43:21<22:58, 21.54s/it, loss=182, v_num=0]\n",
      "Epoch 438/500:  87%|████████▋ | 437/500 [2:43:42<22:38, 21.57s/it, loss=235, v_num=0]\n",
      "Epoch 439/500:  88%|████████▊ | 438/500 [2:44:04<22:15, 21.54s/it, loss=199, v_num=0]\n",
      "Epoch 440/500:  88%|████████▊ | 439/500 [2:44:25<21:54, 21.54s/it, loss=215, v_num=0]\n",
      "Epoch 441/500:  88%|████████▊ | 440/500 [2:44:47<21:32, 21.54s/it, loss=230, v_num=0]\n",
      "Epoch 442/500:  88%|████████▊ | 441/500 [2:45:08<21:12, 21.57s/it, loss=238, v_num=0]\n",
      "Epoch 443/500:  88%|████████▊ | 442/500 [2:45:30<20:52, 21.60s/it, loss=213, v_num=0]\n",
      "Epoch 444/500:  89%|████████▊ | 443/500 [2:45:52<20:33, 21.65s/it, loss=231, v_num=0]\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m WARNING: The neighbor graph has an unexpected format (e.g. computed outside scvelo) \n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m or is corrupted (e.g. due to subsetting). Consider recomputing with `pp.neighbors`.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m computing velocity graph (using 1/24 cores)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m   0%|          | 0/9815 [00:00<?, ?cells/s]\n",
      "Epoch 445/500:  89%|████████▉ | 444/500 [2:46:12<19:50, 21.25s/it, loss=217, v_num=0]\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m     finished (0:00:18) --> added \n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m     'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m computing velocity embedding\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m     finished (0:00:00) --> added\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m     'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m Figure(640x480)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m saving figure to file ./figures/scvelo_n_hidden_256.png\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=701933)\u001b[0m Figure(640x480)\n",
      "Epoch 446/500:  89%|████████▉ | 445/500 [2:46:30<18:38, 20.34s/it, loss=217, v_num=0]\n",
      "Epoch 447/500:  89%|████████▉ | 446/500 [2:46:46<17:08, 19.04s/it, loss=212, v_num=0]\n",
      "Epoch 448/500:  89%|████████▉ | 447/500 [2:47:02<15:58, 18.08s/it, loss=202, v_num=0]\n",
      "Epoch 449/500:  90%|████████▉ | 448/500 [2:47:18<15:06, 17.44s/it, loss=212, v_num=0]\n",
      "Epoch 450/500:  90%|████████▉ | 449/500 [2:47:34<14:26, 17.00s/it, loss=209, v_num=0]\n",
      "Epoch 451/500:  90%|█████████ | 450/500 [2:47:50<13:55, 16.71s/it, loss=207, v_num=0]\n",
      "Epoch 452/500:  90%|█████████ | 451/500 [2:48:06<13:27, 16.49s/it, loss=203, v_num=0]\n",
      "Epoch 453/500:  91%|█████████ | 453/500 [2:48:38<12:41, 16.21s/it, loss=202, v_num=0]\n",
      "Epoch 454/500:  91%|█████████ | 453/500 [2:48:38<12:41, 16.21s/it, loss=202, v_num=0]\n",
      "Epoch 455/500:  91%|█████████ | 454/500 [2:48:54<12:21, 16.11s/it, loss=194, v_num=0]\n",
      "Epoch 456/500:  91%|█████████ | 455/500 [2:49:10<12:02, 16.05s/it, loss=184, v_num=0]\n",
      "Epoch 457/500:  91%|█████████ | 456/500 [2:49:26<11:48, 16.10s/it, loss=173, v_num=0]\n",
      "Epoch 458/500:  91%|█████████▏| 457/500 [2:49:42<11:29, 16.03s/it, loss=167, v_num=0]\n",
      "Epoch 459/500:  92%|█████████▏| 458/500 [2:49:58<11:14, 16.07s/it, loss=171, v_num=0]\n",
      "Epoch 460/500:  92%|█████████▏| 459/500 [2:50:15<11:04, 16.20s/it, loss=171, v_num=0]\n",
      "Epoch 461/500:  92%|█████████▏| 460/500 [2:50:33<11:19, 16.98s/it, loss=147, v_num=0]\n",
      "Epoch 462/500:  92%|█████████▏| 461/500 [2:50:54<11:49, 18.19s/it, loss=174, v_num=0]\n",
      "Epoch 463/500:  92%|█████████▏| 462/500 [2:51:15<11:57, 18.87s/it, loss=181, v_num=0]\n",
      "Epoch 464/500:  93%|█████████▎| 463/500 [2:51:35<11:53, 19.28s/it, loss=179, v_num=0]\n",
      "Epoch 465/500:  93%|█████████▎| 464/500 [2:51:51<10:53, 18.16s/it, loss=185, v_num=0]\n",
      "Epoch 466/500:  93%|█████████▎| 465/500 [2:52:06<10:05, 17.31s/it, loss=139, v_num=0]\n",
      "Epoch 467/500:  93%|█████████▎| 466/500 [2:52:21<09:27, 16.68s/it, loss=151, v_num=0]\n",
      "Epoch 468/500:  93%|█████████▎| 467/500 [2:52:36<08:56, 16.25s/it, loss=168, v_num=0]\n",
      "Epoch 469/500:  94%|█████████▎| 468/500 [2:52:52<08:29, 15.91s/it, loss=167, v_num=0]\n",
      "Epoch 470/500:  94%|█████████▍| 469/500 [2:53:07<08:05, 15.66s/it, loss=151, v_num=0]\n",
      "Epoch 471/500:  94%|█████████▍| 470/500 [2:53:22<07:45, 15.51s/it, loss=180, v_num=0]\n",
      "Epoch 472/500:  94%|█████████▍| 471/500 [2:53:37<07:27, 15.42s/it, loss=172, v_num=0]\n",
      "Epoch 473/500:  94%|█████████▍| 472/500 [2:53:52<07:09, 15.33s/it, loss=165, v_num=0]\n",
      "Epoch 474/500:  95%|█████████▍| 473/500 [2:54:07<06:52, 15.26s/it, loss=165, v_num=0]\n",
      "Epoch 476/500:  95%|█████████▌| 475/500 [2:54:38<06:20, 15.21s/it, loss=128, v_num=0]\n",
      "Epoch 477/500:  95%|█████████▌| 476/500 [2:54:53<06:04, 15.18s/it, loss=141, v_num=0]\n",
      "Epoch 478/500:  95%|█████████▌| 477/500 [2:55:08<05:49, 15.18s/it, loss=127, v_num=0]\n",
      "Epoch 479/500:  96%|█████████▌| 478/500 [2:55:23<05:33, 15.17s/it, loss=161, v_num=0]\n",
      "Epoch 480/500:  96%|█████████▌| 479/500 [2:55:38<05:18, 15.17s/it, loss=177, v_num=0]\n",
      "Epoch 481/500:  96%|█████████▌| 480/500 [2:55:53<05:03, 15.16s/it, loss=182, v_num=0]\n",
      "Epoch 482/500:  96%|█████████▌| 481/500 [2:56:09<04:48, 15.20s/it, loss=147, v_num=0]\n",
      "Epoch 483/500:  96%|█████████▋| 482/500 [2:56:24<04:33, 15.19s/it, loss=123, v_num=0]\n",
      "Epoch 484/500:  97%|█████████▋| 483/500 [2:56:39<04:18, 15.19s/it, loss=117, v_num=0]\n",
      "Epoch 485/500:  97%|█████████▋| 484/500 [2:56:54<04:03, 15.20s/it, loss=125, v_num=0]\n",
      "Epoch 485/500:  97%|█████████▋| 485/500 [2:57:09<05:28, 21.92s/it, loss=158, v_num=0]\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Monitored metric elbo_validation did not improve in the last 45 records. Best score: -3563.934. Signaling Trainer to stop.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m WARNING: The neighbor graph has an unexpected format (e.g. computed outside scvelo) \n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m or is corrupted (e.g. due to subsetting). Consider recomputing with `pp.neighbors`.\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m computing velocity graph (using 1/24 cores)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m   0%|          | 0/9815 [00:00<?, ?cells/s]\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m     finished (0:00:09) --> added \n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m     'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m computing velocity embedding\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m     finished (0:00:00) --> added\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m     'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Figure(640x480)\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m saving figure to file ./figures/scvelo_n_hidden_512.png\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=703982)\u001b[0m Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 23:17:19,814\tERROR tune.py:941 -- Trials did not complete: [train_velovgi_e1172_00002]\n",
      "2023-06-01 23:17:19,814\tINFO tune.py:945 -- Total run time: 10961.59 seconds (10961.54 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "name = \"n_hidden_adjust\"\n",
    "search_space = {\"n_hidden\": tune.grid_search([256, 512, 1024])}\n",
    "results = base.hyperparameter_tuner(name, search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 256}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_result().config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velovi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
