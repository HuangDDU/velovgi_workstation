{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../data/adata//adata.h5ad\n",
      "load ../data/adata//sample_recover.pkl\n"
     ]
    }
   ],
   "source": [
    "import base\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:14:43,291\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-06-01 20:14:44,209\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2023-06-01 20:14:44,250\tINFO tensorboardx.py:172 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-06-01 20:14:44,251\tWARNING callback.py:142 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-06-01 20:14:59</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:14.79        </td></tr>\n",
       "<tr><td>Memory:      </td><td>58.5/62.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Logical resource usage: 1.0/24 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  max_kl_weight</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_velovgi_e4a8b_00000</td><td>RUNNING </td><td>192.168.1.2:704821</td><td style=\"text-align: right;\">            0.6</td></tr>\n",
       "<tr><td>train_velovgi_e4a8b_00001</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">            0.8</td></tr>\n",
       "<tr><td>train_velovgi_e4a8b_00002</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">            1  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=704821)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=704821)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(pid=704821)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(pid=704821)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "\u001b[2m\u001b[36m(pid=704821)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=704821)\u001b[0m load ../data/adata//adata.h5ad\n",
      "\u001b[2m\u001b[36m(pid=704821)\u001b[0m load ../data/adata//sample_recover.pkl\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=704821)\u001b[0m 初始训练，初始化runner参数\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=704821)\u001b[0m choosing neighbor minibatch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_velovgi pid=704821)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=704821)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=704821)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=704821)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_velovgi pid=704821)\u001b[0m Missing logger folder: ./log/max_kl_weight_0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=705188)\u001b[0m Global seed set to 0\n",
      "\u001b[2m\u001b[36m(pid=705188)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(pid=705188)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(pid=705188)\u001b[0m /home/huang/.conda/envs/velovi-env/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "\u001b[2m\u001b[36m(pid=705188)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Task was killed due to the node running low on memory.\nMemory on the node (IP: 192.168.1.2, ID: 0dbdd782c62c607d5ec7ba044feb4feb7048d788b34325fea0f7d6b9) where the task (task ID: ffffffffffffffff8690ae67ae6b73bc6bd8ae0001000000, name=ImplicitFunc.__init__, pid=705188, memory used=0.86GB) was running was 60.08GB / 62.55GB (0.960525), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: a121d3fb99da91dff5abf1ced0b77be9a096d5987cfac029b07b4e9f) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 192.168.1.2`. To see the logs of the worker, use `ray logs worker-a121d3fb99da91dff5abf1ced0b77be9a096d5987cfac029b07b4e9f*out -ip 192.168.1.2. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n695239\t1.93\tray::ImplicitFunc.train\n695240\t1.93\tray::ImplicitFunc.train\n703982\t1.89\tray::ImplicitFunc.train\n704886\t1.86\tray::ImplicitFunc.train\n695163\t1.84\tray::ImplicitFunc.train\n674446\t1.82\tray::ImplicitFunc.train\n702823\t1.81\tray::ImplicitFunc.train\n674518\t1.81\tray::ImplicitFunc.train\n697513\t1.79\tray::ImplicitFunc.train\n674519\t1.79\tray::ImplicitFunc.train\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmax_kl_weight_adjust\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m search_space \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmax_kl_weight\u001b[39m\u001b[39m\"\u001b[39m: tune\u001b[39m.\u001b[39mgrid_search([\u001b[39m0.6\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m1.0\u001b[39m])}\n\u001b[0;32m----> 3\u001b[0m results \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39;49mhyperparameter_tuner(name, search_space)\n",
      "File \u001b[0;32m~/PyCode/scRNA/Other/velovgi_workstation/notebook/lab_server/erythroid_lineage/0.调参/base.py:115\u001b[0m, in \u001b[0;36mhyperparameter_tuner\u001b[0;34m(name, search_space)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhyperparameter_tuner\u001b[39m(name, search_space):\n\u001b[1;32m    101\u001b[0m     tuner \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39mTuner(\n\u001b[1;32m    102\u001b[0m         train_velovgi,\n\u001b[1;32m    103\u001b[0m         tune_config\u001b[39m=\u001b[39mtune\u001b[39m.\u001b[39mTuneConfig(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m         param_space\u001b[39m=\u001b[39msearch_space,\n\u001b[1;32m    113\u001b[0m     )\n\u001b[0;32m--> 115\u001b[0m     results \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m    116\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/tuner.py:367\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_ray_client:\n\u001b[1;32m    366\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_local_tuner\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m    368\u001b[0m     \u001b[39mexcept\u001b[39;00m TuneError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    369\u001b[0m         \u001b[39mraise\u001b[39;00m TuneError(\n\u001b[1;32m    370\u001b[0m             _TUNER_FAILED_MSG\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    371\u001b[0m                 path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_tuner\u001b[39m.\u001b[39mget_experiment_checkpoint_dir()\n\u001b[1;32m    372\u001b[0m             )\n\u001b[1;32m    373\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/impl/tuner_internal.py:503\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m param_space \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_space)\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_restored:\n\u001b[0;32m--> 503\u001b[0m     analysis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_internal(trainable, param_space)\n\u001b[1;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     analysis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resume(trainable, param_space)\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/impl/tuner_internal.py:621\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39m\"\"\"Fitting for a fresh Tuner.\"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m args \u001b[39m=\u001b[39m {\n\u001b[1;32m    609\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[1;32m    610\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tuner_kwargs,\n\u001b[1;32m    620\u001b[0m }\n\u001b[0;32m--> 621\u001b[0m analysis \u001b[39m=\u001b[39m run(\n\u001b[1;32m    622\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    623\u001b[0m )\n\u001b[1;32m    624\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclear_remote_string_queue()\n\u001b[1;32m    625\u001b[0m \u001b[39mreturn\u001b[39;00m analysis\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/tune.py:906\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue, _tuner_api)\u001b[0m\n\u001b[1;32m    904\u001b[0m runner\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    905\u001b[0m \u001b[39mif\u001b[39;00m has_verbosity(Verbosity\u001b[39m.\u001b[39mV1_EXPERIMENT):\n\u001b[0;32m--> 906\u001b[0m     _report_progress(runner, progress_reporter)\n\u001b[1;32m    908\u001b[0m \u001b[39mif\u001b[39;00m air_verbosity:\n\u001b[1;32m    909\u001b[0m     _report_air_progress(runner, air_progress_reporter)\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/tune.py:166\u001b[0m, in \u001b[0;36m_report_progress\u001b[0;34m(runner, reporter, done)\u001b[0m\n\u001b[1;32m    164\u001b[0m sched_debug_str \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39mscheduler_alg\u001b[39m.\u001b[39mdebug_string()\n\u001b[1;32m    165\u001b[0m used_resources_str \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39m_used_resources_string()\n\u001b[0;32m--> 166\u001b[0m reporter\u001b[39m.\u001b[39;49mreport(trials, done, sched_debug_str, used_resources_str)\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/progress_reporter.py:550\u001b[0m, in \u001b[0;36mJupyterNotebookReporter.report\u001b[0;34m(self, trials, done, *sys_info)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreport\u001b[39m(\u001b[39mself\u001b[39m, trials: List[Trial], done: \u001b[39mbool\u001b[39m, \u001b[39m*\u001b[39msys_info: Dict):\n\u001b[0;32m--> 550\u001b[0m     progress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_progress_html(trials, done, \u001b[39m*\u001b[39;49msys_info)\n\u001b[1;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_queue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    553\u001b[0m         \u001b[39m# If an output queue is set, send string\u001b[39;00m\n\u001b[1;32m    554\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_queue\u001b[39m.\u001b[39mput(progress)\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/progress_reporter.py:586\u001b[0m, in \u001b[0;36mJupyterNotebookReporter._progress_html\u001b[0;34m(self, trials, done, *sys_info)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39m\"\"\"Generate an HTML-formatted progress update.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \n\u001b[1;32m    572\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39m        - Trial progress table, with information about each experiment\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics_override:\n\u001b[0;32m--> 586\u001b[0m     user_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_user_metrics(trials, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_limit)\n\u001b[1;32m    587\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_columns\u001b[39m.\u001b[39mupdate(user_metrics)\n\u001b[1;32m    589\u001b[0m current_time, running_for \u001b[39m=\u001b[39m _get_time_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time, time\u001b[39m.\u001b[39mtime())\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/progress_reporter.py:398\u001b[0m, in \u001b[0;36mTuneReporterBase._infer_user_metrics\u001b[0;34m(self, trials, limit)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_metrics \u001b[39m=\u001b[39m {}\n\u001b[1;32m    397\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m trials:\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39;49mlast_result:\n\u001b[1;32m    399\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     \u001b[39mfor\u001b[39;00m metric, value \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mlast_result\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/experiment/trial.py:594\u001b[0m, in \u001b[0;36mTrial.last_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_result\n\u001b[1;32m    593\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m {k \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m result \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m TRIAL_ID}:\n\u001b[0;32m--> 594\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_default_result_or_future()\n\u001b[1;32m    595\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_result_or_future \u001b[39mor\u001b[39;00m result\n\u001b[1;32m    596\u001b[0m result\u001b[39m.\u001b[39msetdefault(TRIAL_ID, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrial_id)\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/tune/experiment/trial.py:562\u001b[0m, in \u001b[0;36mTrial._get_default_result_or_future\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_result_or_future \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    559\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_result_or_future, ray\u001b[39m.\u001b[39mObjectRef\n\u001b[1;32m    560\u001b[0m ):\n\u001b[1;32m    561\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_result_or_future \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_result_or_future)\n\u001b[1;32m    563\u001b[0m     \u001b[39mexcept\u001b[39;00m RayActorError:  \u001b[39m# error during initialization\u001b[39;00m\n\u001b[1;32m    564\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_result_or_future \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/velovi-env/lib/python3.8/site-packages/ray/_private/worker.py:2523\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2521\u001b[0m             \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2522\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2523\u001b[0m             \u001b[39mraise\u001b[39;00m value\n\u001b[1;32m   2525\u001b[0m \u001b[39mif\u001b[39;00m is_individual_id:\n\u001b[1;32m   2526\u001b[0m     values \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 192.168.1.2, ID: 0dbdd782c62c607d5ec7ba044feb4feb7048d788b34325fea0f7d6b9) where the task (task ID: ffffffffffffffff8690ae67ae6b73bc6bd8ae0001000000, name=ImplicitFunc.__init__, pid=705188, memory used=0.86GB) was running was 60.08GB / 62.55GB (0.960525), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: a121d3fb99da91dff5abf1ced0b77be9a096d5987cfac029b07b4e9f) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 192.168.1.2`. To see the logs of the worker, use `ray logs worker-a121d3fb99da91dff5abf1ced0b77be9a096d5987cfac029b07b4e9f*out -ip 192.168.1.2. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n695239\t1.93\tray::ImplicitFunc.train\n695240\t1.93\tray::ImplicitFunc.train\n703982\t1.89\tray::ImplicitFunc.train\n704886\t1.86\tray::ImplicitFunc.train\n695163\t1.84\tray::ImplicitFunc.train\n674446\t1.82\tray::ImplicitFunc.train\n702823\t1.81\tray::ImplicitFunc.train\n674518\t1.81\tray::ImplicitFunc.train\n697513\t1.79\tray::ImplicitFunc.train\n674519\t1.79\tray::ImplicitFunc.train\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-01 20:15:43,261 E 703924 703924] (raylet) node_manager.cc:3071: 4 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 0dbdd782c62c607d5ec7ba044feb4feb7048d788b34325fea0f7d6b9, IP: 192.168.1.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 192.168.1.2`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "name = \"max_kl_weight_adjust\"\n",
    "search_space = {\"max_kl_weight\": tune.grid_search([0.6, 0.8, 1.0])}\n",
    "results = base.hyperparameter_tuner(name, search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 1024}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_result().config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velovi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
